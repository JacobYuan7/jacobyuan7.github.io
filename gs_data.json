{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "jQ3bFDMAAAAJ&hl=en&oi=ao", "source": "AUTHOR_PROFILE_PAGE", "name": "Hangjie Yuan", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=jQ3bFDMAAAAJ&citpid=1", "affiliation": "Alibaba DAMO | ZJU | MMLab@NTU", "organization": 1118375729466322660, "interests": ["Generative Models", "Multimodal Models", "Foundation Models", "Video Understanding"], "email_domain": "@zju.edu.cn", "homepage": "https://jacobyuan7.github.io/", "citedby": 3022, "publications": {"jQ3bFDMAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ModelScope Text-to-Video Technical Report", "pub_year": "2023"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:eQOLeE2rZwMC", "num_citations": 712, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16637655185374124709,15748570192079678361,8129232926776093602", "cites_id": ["16637655185374124709", "15748570192079678361", "8129232926776093602"]}, "jQ3bFDMAAAAJ:hFOr9nPyWt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Videocomposer: Compositional video synthesis with motion controllability", "pub_year": "2023"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:hFOr9nPyWt4C", "num_citations": 511, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4718948689901741293", "cites_id": ["4718948689901741293"]}, "jQ3bFDMAAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "I2vgen-xl: High-quality image-to-video synthesis via cascaded diffusion models", "pub_year": "2023"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:Wp0gIr-vW9MC", "num_citations": 343, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5568396991815087432,11333354864691107304", "cites_id": ["5568396991815087432", "11333354864691107304"]}, "jQ3bFDMAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DreamVideo: Composing Your Dream Videos with Customized Subject and Motion", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:hqOjcs7Dif8C", "num_citations": 189, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1817249841093338020,7996693963193869661", "cites_id": ["1817249841093338020", "7996693963193869661"]}, "jQ3bFDMAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Overcoming Catastrophic Forgetting in Incremental Object Detection via Elastic Response Distillation", "pub_year": "2022"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:9yKSN-GCB0IC", "num_citations": 185, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1433907519873386658,1470627051793527853", "cites_id": ["1433907519873386658", "1470627051793527853"]}, "jQ3bFDMAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Spatio-Temporal Dynamic Inference Network for Group Activity Recognition", "pub_year": "2021"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:4TOpqqG69KYC", "num_citations": 146, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=867650602514978215,7732359772286922945", "cites_id": ["867650602514978215", "7732359772286922945"]}, "jQ3bFDMAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RLIP: Relational Language-Image Pre-training for Human-Object Interaction Detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:UeHWp8X0CEIC", "num_citations": 111, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15237439848602268466", "cites_id": ["15237439848602268466"]}, "jQ3bFDMAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "InstructVideo: Instructing Video Diffusion Models with Human Feedback", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:0EnyYjriUFMC", "num_citations": 95, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5669627041012255978", "cites_id": ["5669627041012255978"]}, "jQ3bFDMAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Visual Context for Group Activity Recognition", "pub_year": "2021"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:2osOgNQ5qMEC", "num_citations": 92, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2108902506692434453", "cites_id": ["2108902506692434453"]}, "jQ3bFDMAAAAJ:maZDTaKrznsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Worldvla: Towards autoregressive action world model", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:maZDTaKrznsC", "num_citations": 86, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15619447321127946082,9997448240852426242", "cites_id": ["15619447321127946082", "9997448240852426242"]}, "jQ3bFDMAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RLIPv2: Fast Scaling of Relational Language-Image Pre-training", "pub_year": "2023"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:WF5omc3nYNoC", "num_citations": 80, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2624019884095360120,9669132763982111382", "cites_id": ["2624019884095360120", "9669132763982111382"]}, "jQ3bFDMAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Recipe for Scaling up Text-to-Video Generation with Text-free Videos", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:8k81kl-MbHgC", "num_citations": 74, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5319597752904683656", "cites_id": ["5319597752904683656"]}, "jQ3bFDMAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Detecting Human-Object Interactions with Object-Guided Cross-Modal Calibrated Semantics", "pub_year": "2022"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:u-x6o8ySG0sC", "num_citations": 53, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=107667672590747781", "cites_id": ["107667672590747781"]}, "jQ3bFDMAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "From Denoising Training to Test-Time Adaptation: Enhancing Domain Generalization for Medical Image Segmentation", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:5nxA0vEk-isC", "num_citations": 47, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17213070336290495734", "cites_id": ["17213070336290495734"]}, "jQ3bFDMAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generative artificial intelligence in robotic manipulation: A survey", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:TQgYirikUcIC", "num_citations": 33, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10452553030188386786", "cites_id": ["10452553030188386786"]}, "jQ3bFDMAAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Make Continual Learning Stronger via C-Flat", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:M3ejUd6NZC8C", "num_citations": 32, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3393886655885522996", "cites_id": ["3393886655885522996"]}, "jQ3bFDMAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:7PzlFSSx8tAC", "num_citations": 30, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18113282090681998442,11295712379270824992", "cites_id": ["18113282090681998442", "11295712379270824992"]}, "jQ3bFDMAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Revisiting Neural Networks for Continual Learning: An Architectural Perspective", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:qxL8FJ1GzNcC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14420115439691905701", "cites_id": ["14420115439691905701"]}, "jQ3bFDMAAAAJ:M3NEmzRMIkIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumos-1: On autoregressive video generation from a unified model perspective", "pub_year": "2026"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:M3NEmzRMIkIC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1029106512358670844", "cites_id": ["1029106512358670844"]}, "jQ3bFDMAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Frequency Autoregressive Image Generation with Continuous Tokens", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:e5wmG9Sq2KIC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2082586221142396211", "cites_id": ["2082586221142396211"]}, "jQ3bFDMAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Few-shot Action Recognition with Captioning Foundation Models", "pub_year": "2023"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:roLk4NBRz8UC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5030670456473451371", "cites_id": ["5030670456473451371"]}, "jQ3bFDMAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DreamRelation: Relation-Centric Video Customization", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:_Qo2XoVZTnwC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1716783835749131157", "cites_id": ["1716783835749131157"]}, "jQ3bFDMAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Mask-Robust Face Recognition", "pub_year": "2021"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:qjMakFHDy7sC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6699402309201135650", "cites_id": ["6699402309201135650"]}, "jQ3bFDMAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:ZeXyd9-uunAC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16351651068269439743", "cites_id": ["16351651068269439743"]}, "jQ3bFDMAAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ZeroFlow: Overcoming Catastrophic Forgetting is Easier than You Think", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:qUcmZB5y_30C", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17347882477340755873,8284540998789637817", "cites_id": ["17347882477340755873", "8284540998789637817"]}, "jQ3bFDMAAAAJ:isC4tDSrTZIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VideoMAR: Autoregressive Video Generatio with Continuous Tokens", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:isC4tDSrTZIC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12380965890005031348", "cites_id": ["12380965890005031348"]}, "jQ3bFDMAAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:HDshCWvjkbEC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1473995336727760138", "cites_id": ["1473995336727760138"]}, "jQ3bFDMAAAAJ:vV6vV6tmYwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aerogto: An efficient graph-transformer operator for learning large-scale aerodynamics of 3d vehicle geometries", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:vV6vV6tmYwMC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17914404063221543398", "cites_id": ["17914404063221543398"]}, "jQ3bFDMAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Progressive learning without forgetting", "pub_year": "2022"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:IjCSPb-OGe4C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2419804766727454479", "cites_id": ["2419804766727454479"]}, "jQ3bFDMAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EvolveDirector: Approaching Advanced Text-to-Image Generation with Large Vision-Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:dhFuZR0502QC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7776721284200873862", "cites_id": ["7776721284200873862"]}, "jQ3bFDMAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UniGrad-FS: Unified Gradient Projection With Flatter Sharpness for Continual Learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:mVmsd5A6BfQC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12807530465098397956", "cites_id": ["12807530465098397956"]}, "jQ3bFDMAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MathFlow: Enhancing the Perceptual Flow of MLLMs for Visual Mathematical Problems", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:RHpTSmoSYBkC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15845066629927736056", "cites_id": ["15845066629927736056"]}, "jQ3bFDMAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PAPM: A Physics-aware Proxy Model for Process Systems", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:kNdYIx-mwKoC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1065915363133201743", "cites_id": ["1065915363133201743"]}, "jQ3bFDMAAAAJ:RGFaLdJalmkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rynnvla-002: A unified vision-language-action and world model", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:RGFaLdJalmkC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7641453366133280732", "cites_id": ["7641453366133280732"]}, "jQ3bFDMAAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FreeMask: Rethinking the Importance of Attention Masks for Zero-Shot Video Editing", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:QIV2ME_5wuYC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6243815923966937921", "cites_id": ["6243815923966937921"]}, "jQ3bFDMAAAAJ:YFjsv_pBGBYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Routing matters in moe: Scaling diffusion transformers with explicit routing guidance", "pub_year": "2026"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:YFjsv_pBGBYC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9349100471996515985", "cites_id": ["9349100471996515985"]}, "jQ3bFDMAAAAJ:J_g5lzvAfSwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "C-flat++: Towards a more efficient and powerful framework for continual learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:J_g5lzvAfSwC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5237388365083037876,7960934684582983490", "cites_id": ["5237388365083037876", "7960934684582983490"]}, "jQ3bFDMAAAAJ:ldfaerwXgEUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving", "pub_year": "2026"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:ldfaerwXgEUC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15362071109265900554", "cites_id": ["15362071109265900554"]}, "jQ3bFDMAAAAJ:blknAaTinKkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:blknAaTinKkC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4622700244424515870", "cites_id": ["4622700244424515870"]}, "jQ3bFDMAAAAJ:k_IJM867U9cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:k_IJM867U9cC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13284298839122551564", "cites_id": ["13284298839122551564"]}, "jQ3bFDMAAAAJ:NaGl4SEjCO4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Branch, or Layer? Zeroth-Order Optimization for Continual Learning of Vision-Language Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:NaGl4SEjCO4C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3881842393611895930", "cites_id": ["3881842393611895930"]}, "jQ3bFDMAAAAJ:RYcK_YlVTxYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lumosflow: Motion-guided long video generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:RYcK_YlVTxYC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8134080912719307012", "cites_id": ["8134080912719307012"]}, "jQ3bFDMAAAAJ:pqnbT2bcN3wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Why Does RL Generalize Better Than SFT? A Data-Centric Perspective on VLM Post-Training", "pub_year": "2026"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:pqnbT2bcN3wC", "num_citations": 0}, "jQ3bFDMAAAAJ:ZHo1McVdvXMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MCIE: Multimodal LLM-Driven Complex Instruction Image Editing with Spatial Guidance", "pub_year": "2026"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:ZHo1McVdvXMC", "num_citations": 0}, "jQ3bFDMAAAAJ:M05iB0D1s5AC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Continual GUI Agents", "pub_year": "2026"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:M05iB0D1s5AC", "num_citations": 0}, "jQ3bFDMAAAAJ:2P1L_qKh6hAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "An Efficient Graph-Transformer Operator for Learning Physical Dynamics with Manifolds Embedding", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:2P1L_qKh6hAC", "num_citations": 0}, "jQ3bFDMAAAAJ:70eg2SAEIzsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:70eg2SAEIzsC", "num_citations": 0}, "jQ3bFDMAAAAJ:BqipwSGYUEgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:BqipwSGYUEgC", "num_citations": 0}, "jQ3bFDMAAAAJ:bEWYMUwI8FkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adapt before Continual Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:bEWYMUwI8FkC", "num_citations": 0}, "jQ3bFDMAAAAJ:GnPB-g6toBAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Taming Consistency Distillation for Accelerated Human Image Animation", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:GnPB-g6toBAC", "num_citations": 0}, "jQ3bFDMAAAAJ:lSLTfruPkqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SAMora: Enhancing SAM through Hierarchical Self-Supervised Pre-Training for Medical Images", "pub_year": "2025"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:lSLTfruPkqcC", "num_citations": 0}, "jQ3bFDMAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth Limited Optical Signal Acquisition", "pub_year": "2024"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:3fE2CSJIrl8C", "num_citations": 0}, "jQ3bFDMAAAAJ:rO6llkc54NcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LumosX: Relate Any Identities with Their Attributes for Personalized Video Generation"}, "filled": false, "author_pub_id": "jQ3bFDMAAAAJ:rO6llkc54NcC", "num_citations": 0}}, "citedby5y": 3021, "hindex": 19, "hindex5y": 19, "i10index": 25, "i10index5y": 25, "cites_per_year": {"2022": 56, "2023": 191, "2024": 914, "2025": 1692, "2026": 165}, "updated": "2026-02-20 08:49:39.023356"}